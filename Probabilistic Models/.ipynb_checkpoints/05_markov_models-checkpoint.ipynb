{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7727dcb-7e8b-488b-8d01-d93d50cbec24",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Markov Models</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7b134-3aae-4361-9276-f22686df6a49",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> The Markov Property</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A Propriedade de Markov é uma assunção de que um determinado evento depende apenas de seu antecessor direto, sendo independente assim, de todos os demais acontecimentos do passado.\n",
    "            <center style='margin-top:20px'> \n",
    "                 $p(x_{t}|x_{t-1},x_{t-2},...)=p(x_{t}|x_{t-1})$\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd068e4-a96a-4bda-8501-709df15cb25b",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> The Markov Model</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O Modelo de Markov é um conjunto de probabilidades de migrarmos de uma situação para outra. Chamamos as situações, nesse contexto, de \"estados\".\n",
    "        </li>\n",
    "        <li>\n",
    "            Os Modelos de Markov respeitam a Propriedade de Markov. Por isso, podemos representar as probabilidades de transição em uma matriz quadrada (N é a quantidade de estados possíveis em nosso estudo). Os índices das linhas são os estados iniciais, enquanto os das colunas, de destino.\n",
    "            <center style='margin-top:20px'> \n",
    "                $A_{i,j}=p(s_{t}=j|s_{t-1}=i), \\forall{i=1\\dots{N}, j=1\\dots N}$\n",
    "            </center>\n",
    "        </li>\n",
    "        <li style='margin-top:20px'>\n",
    "            Perceba que os números de A sempre serão os mesmos, independentemente do valor de t. Falamos que lidamos com um Processo de Markov homogêneo ao tempo.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8333222-27ce-4222-81a0-47b2b65d79a0",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Initial State</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A probabilidade do primeiro estado da sequência não pode estar em A, porque ele não tem antecessor.\n",
    "        </li>\n",
    "        <li>\n",
    "            Nesse caso, armazenamos essas proporções em um vetor $\\pi$.\n",
    "            <center style='margin-top:20px'> \n",
    "                $\\pi_{i}=p(s_{1}=i) \\forall{i=1 \\dots{M}}$ (sendo $M$ a quantidade total de estados)\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcacdafb-cf70-411f-a257-ba960c484fcd",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Montagem de $A$ e $\\pi$</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A criação dessas ordenações envolve meramente o cálculo de probabilidades envolvendo os tokens.\n",
    "            <center style='margin-top:20px'> \n",
    "                $A_{i,j}=\\frac{\\text{count}(i\\to{j})}{\\text{count}(i)}$\n",
    "            </center>\n",
    "            <center style='margin-top:20px'> \n",
    "                $\\pi_{i}=\\frac{\\text{count}(s_{1}=i)}{N}$, sendo $N$ o tamanho do dataset.\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2c12b9a-38cd-44d7-a737-72fa3bacf98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oi,        0.666667\n",
       "caramba    0.333333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class MarkovModel:\n",
    "    '''\n",
    "        Modelo de Markov, com Add-Epsilon Smoothing.\n",
    "\n",
    "        Parâmetro\n",
    "        ---------\n",
    "        `corpus`: List[str]\n",
    "            Lista com os documentos a serem usados.\n",
    "        `epsilon`: float\n",
    "            Grau de suavização das probabilidades.\n",
    "    '''\n",
    "    def __init__(self, corpus:List[str], epsilon:float):\n",
    "        self.corpus = self.split_corpus(corpus)\n",
    "        self.corpus_length = len(self.corpus)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    @staticmethod\n",
    "    def split_corpus(corpus:List[str])->List[List[str]]:\n",
    "        '''\n",
    "            Função que tokeniza os documentos do corpus.\n",
    "        '''\n",
    "        return [document.split() for document in corpus]\n",
    "\n",
    "    def __vocab(self)->set:\n",
    "        '''\n",
    "            Extração dos termos únicos do nosso corpus.\n",
    "        '''\n",
    "        vocab = []\n",
    "        for doc in self.corpus:\n",
    "            vocab+=doc[1:] # Not including the first tokens.\n",
    "        return set(vocab)\n",
    "        \n",
    "\n",
    "    def __pi(self)->pd.Series:\n",
    "        '''\n",
    "            Mensuração do vetor pi do Modelo de Markov\n",
    "\n",
    "            Retorna\n",
    "            -------\n",
    "            Uma `pd.Series` com as probabilidades de pi.\n",
    "        '''\n",
    "        self._pi = {}\n",
    "        for doc in self.corpus:\n",
    "            i = doc[0]\n",
    "            if i not in self._pi.keys():\n",
    "                self._pi[i] = 1\n",
    "            else:\n",
    "                self._pi[i]+=1\n",
    "        #self._pi = {i:count/self.corpus_length for i, count in self._pi.items()}\n",
    "        m = self.__a().shape[0]\n",
    "        return (pd.Series(self._pi)+self.epsilon) / (self.corpus_length+self.epsilon*m)\n",
    "        \n",
    "    def __a(self)->pd.DataFrame:\n",
    "        '''\n",
    "            Mensuração da matriz A, de um Modelo de Markov.\n",
    "\n",
    "            Retorna\n",
    "            -------\n",
    "            Um `pd.DataFrame` com as probabilidades de transição de estado.\n",
    "        '''\n",
    "        self._a = {j:{} for j in self.__vocab()}\n",
    "        for doc in self.corpus:\n",
    "            for idx, j in enumerate(doc[1:], start=1):\n",
    "                d_j = self._a[j]\n",
    "                i = doc[idx-1]\n",
    "                if i not in d_j.keys():\n",
    "                    d_j[i] = 1\n",
    "                else:\n",
    "                    d_j[i] += 1\n",
    "        \n",
    "        a = pd.DataFrame(self._a).fillna(0)\n",
    "        num = (a+self.epsilon)\n",
    "        denom = a.sum(axis=1, skipna=True)+a.shape[0]*self.epsilon\n",
    "        return num.div(denom, axis=0) \n",
    "\n",
    "    def transform(self):\n",
    "        return self.__pi()\n",
    "\n",
    "a = MarkovModel(['oi, tudo bem','oi, tudo ótimo' , 'oi, tchau', 'caramba'], 1)\n",
    "a.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f3cdd-8a3d-4b75-a20a-24b7270f99b2",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Probability Smoothing and Log-Probabilities</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A desvantagem do Modelo de Markov Clássico é que ele confere probabilidade 0 para sequências que contenham transições de estado não vistas em treinamento. \n",
    "        </li>\n",
    "        <li>\n",
    "            O que podemos fazer é acrescentar uma pequena adaptação no cálculo das probabilidades, conhecida como Add-Epsilon Smoothing. Quanto maior $\\epsilon$, mais suavizadas as probabilidades ficam:\n",
    "            <center style='margin-top:20px'> \n",
    "                $A_{i,j}=\\frac{\\text{count}(i\\to{j})+\\epsilon}{\\text{count}(i)+\\epsilon{M}}$\n",
    "            </center>\n",
    "            <center style='margin-top:20px'> \n",
    "                $\\pi_{i}=\\frac{\\text{count}(s_{1}=i)+\\epsilon}{N+\\epsilon{M}}$\n",
    "            </center>\n",
    "        </li>\n",
    "        <li style='margin-top:20px'>\n",
    "            Observe que a classe da aula passada já está adaptado para esse smoothing.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1b751-f625-4289-babc-53e7033ea860",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Working with Log Probabilities</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Quando mensuramos a probabilidade de uma sequência, é comum o fazermos com os logs das probabilidades de cada estado. Isso porque os computadores podem arredondar o resultado de sequências muito longas para zero.\n",
    "        </li>\n",
    "        <li>\n",
    "            Nesse contexto, mensurar a probabilidade da sequência se dará com a soma dos logs das probabilidades, em consonância com a propriedade $\\log{(AB)}=\\log{A}+\\log{B}$\n",
    "            <center style='margin-top:20px'> \n",
    "                $\\displaystyle \\log{p(s_{1...T})}=\\log{\\pi_{s_{1}}}+\\sum_{t=2}^{T}\\log{A_{s_{t-1,s_{t}}}}$ \n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5cdb12-2d9e-4f93-85a0-55370cc9b938",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Building a Text Classifier (Theory)</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Faremos agora um projeto de classificação de poemas. Montaremos dois Modelos de Markov, um treinado com textos de Edgar Allan Poe, e outro com os de Robert Frost.\n",
    "        </li>\n",
    "        <li>\n",
    "            Por fim, passaremos uma sequência a ambos os modelos. Eles nos retornarão a probabilidade $p(\\text{texto}|\\text{autor})$; usaremos o Teorema de Bayes para conseguirmos computar a $p(\\text{autor}|\\text{texto})$.\n",
    "        </li>\n",
    "        <li>\n",
    "            Por fim, nossa classificação será feita com $\\displaystyle \\text{autor}^{*}=\\text{argmax}_{autor}\\text{ }{p(\\text{autor}|\\text{texto})}$\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a06fe-2932-4d8f-8cd7-b625b11169bd",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Language Model (Theory)</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Nós agora utilizaremos um Modelo de Markov para geração de textos.\n",
    "        </li>\n",
    "        <li>\n",
    "            Isso será feito aproveitando o fato de Modelos de Markov serem modelos generativos - ou seja, aprendem uma certa distribuição de probabilidades $p(x|y)$.\n",
    "            <center style='margin-top:20px'> \n",
    "                <img src='../img/05_models.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23210672-b2b9-41e0-9130-a9f8f2502588",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Sampling</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Podemos escrever o texto com funções do `numpy.random`. Isso garantirá que poderemos escrever textos diversos, sem necessariamente escolher o token mais provável todas as vezes.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8a868-58e3-459a-b671-91f80260d397",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> 2-nd Order Markov Model</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Considerar apenas o último token na escrita pode tornar nosso modelo frágil, criando textos incoesos e incoerentes. Podemos torná-lo mais robusto oferecendo a ele mais contexto.\n",
    "        </li>\n",
    "        <li>\n",
    "            Caso também ofereçamos a penúltima palavra do texto, estaremos criando um <i>Modelo de Markov de Segunda Ordem</i>. No caso, ele receberá uma terceira matriz de transição de estados com uma terceira dimensão.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bdf10-7fc6-42fb-88cc-76c53b950ff7",
   "metadata": {},
   "source": [
    "<center style='margin-top:20px'> \n",
    "    <figure>\n",
    "        <img src='../img/05_second_markov.png'>\n",
    "        <figcaption> Observe que ainda deveremos ter uma matriz 2-D, para o segundo token da sentença.</figcaption>\n",
    "    </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd37074f-f1fa-4798-8d81-3abac3e2c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "05_second_markov.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcbaf6-23f2-45c9-8bba-b348fa37bb3f",
   "metadata": {},
   "source": [
    "<p style='color:red'> Terminei o projeto; Aula 39 (1:55)</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
