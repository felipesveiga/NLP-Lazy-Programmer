{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17eec26",
   "metadata": {
    "papermill": {
     "duration": 0.003907,
     "end_time": "2024-04-10T09:42:50.666515",
     "exception": false,
     "start_time": "2024-04-10T09:42:50.662608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Poem Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e1a213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T09:42:50.676046Z",
     "iopub.status.busy": "2024-04-10T09:42:50.675100Z",
     "iopub.status.idle": "2024-04-10T09:42:50.710087Z",
     "shell.execute_reply": "2024-04-10T09:42:50.708887Z"
    },
    "papermill": {
     "duration": 0.043291,
     "end_time": "2024-04-10T09:42:50.713188",
     "exception": false,
     "start_time": "2024-04-10T09:42:50.669897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from typing import List\n",
    "\n",
    "def load_text(filename:str)->List[str]:\n",
    "    '''\n",
    "        Reads the .txt file.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        `filename`: str\n",
    "            The name of the poems file.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        A list containing each strophe's content.\n",
    "    '''\n",
    "    with open(f'/kaggle/input/poe-vs-frost/{filename}', 'r') as f:\n",
    "        strophe_delim = '\\n\\n'\n",
    "        return sub('\\n\\u2009\\n', strophe_delim, f.read()).split(strophe_delim)\n",
    "    \n",
    "txt_frost = load_text('05_robert_frost.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e63b8",
   "metadata": {
    "papermill": {
     "duration": 0.002983,
     "end_time": "2024-04-10T09:42:50.719589",
     "exception": false,
     "start_time": "2024-04-10T09:42:50.716606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Text Treatment\n",
    "* Text Normalization, \\<EOS\\> tag and turning new line a valid character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb65510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T09:42:50.728495Z",
     "iopub.status.busy": "2024-04-10T09:42:50.727836Z",
     "iopub.status.idle": "2024-04-10T09:42:52.931371Z",
     "shell.execute_reply": "2024-04-10T09:42:52.930348Z"
    },
    "papermill": {
     "duration": 2.211425,
     "end_time": "2024-04-10T09:42:52.934141",
     "exception": false,
     "start_time": "2024-04-10T09:42:50.722716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from re import sub\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def remove_punctuation(s:str)->str:\n",
    "    '''\n",
    "        Removes punctuation from a string.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        s: `str`\n",
    "            The provided string.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The treated string.\n",
    "    '''\n",
    "        \n",
    "    translation_table = str.maketrans('', '', string.punctuation)\n",
    "    return s.lower().strip().translate(translation_table)\n",
    "\n",
    "def eos(s:str)->str:\n",
    "    '''\n",
    "        Creates an End-Of-Sentence tag at the end of the string.\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        s: `str`\n",
    "            The provided string.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The treated string.\n",
    "    '''\n",
    "    return s+' <eos>' if '<eos>' not in s else s\n",
    "\n",
    "def new_line(s:str)->str:\n",
    "    '''\n",
    "        Turns \\n character a token\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        s: `str`\n",
    "            The provided string.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The treated string.\n",
    "    '''\n",
    "    return sub('\\n', ' \\n ', s)\n",
    "    \n",
    "def treat(s:str)->str:\n",
    "    '''\n",
    "        Applies all transformations mentioned above in a text.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        s: `str`\n",
    "            The provided string.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The treated string.\n",
    "    '''\n",
    "    s = remove_punctuation(s)\n",
    "    s = eos(s)\n",
    "    s = new_line(s)\n",
    "    return s.split()\n",
    "\n",
    "txt_frost = list(map(treat, txt_frost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe91a84",
   "metadata": {
    "papermill": {
     "duration": 0.002958,
     "end_time": "2024-04-10T09:42:52.940501",
     "exception": false,
     "start_time": "2024-04-10T09:42:52.937543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating the Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf65ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T09:42:52.949719Z",
     "iopub.status.busy": "2024-04-10T09:42:52.948518Z",
     "iopub.status.idle": "2024-04-10T09:42:53.022258Z",
     "shell.execute_reply": "2024-04-10T09:42:53.020771Z"
    },
    "papermill": {
     "duration": 0.081442,
     "end_time": "2024-04-10T09:42:53.025107",
     "exception": false,
     "start_time": "2024-04-10T09:42:52.943665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i walked down alone sunday after church to the knob and hold his highest feat on some wild apple trees young tender bark what well may prove the years high girdle mark\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "class MarkovModel:\n",
    "    \n",
    "    def __pi(self, X:List[str]):\n",
    "        self.pi = Counter(x[0] for x in X)\n",
    "        self.pi = {token:count/len(X) for token, count in self.pi.items()}\n",
    "        \n",
    "    def __a(self, X:List[str]):\n",
    "        counter = Counter(x[0]+'<sep>'+x[1] for x in X) \n",
    "        denom = Counter(x[0] for x in X)\n",
    "        self.a = {}\n",
    "        for key in counter.keys():\n",
    "            i,j = key.split('<sep>')\n",
    "            if i not in self.a.keys():\n",
    "                self.a[i] = {}\n",
    "            self.a[i][j] = counter[key]/denom[i]\n",
    "        \n",
    "            \n",
    "    def __a2(self, X:List[str]):\n",
    "        counter = Counter(x[i-2]+'<sep>'+x[i-1]+'<sep>'+x[i] for x in X for i in range(2, len(x)))\n",
    "        denom = Counter(x[i-1]+'<sep>'+x[i] for x in X for i in range(1, len(x)-1))\n",
    "        self.a2 = {}\n",
    "        for key in counter.keys():\n",
    "            i,j,k = key.split('<sep>')\n",
    "            if i not in self.a2.keys():\n",
    "                self.a2[i] = {}\n",
    "            if j not in self.a2[i].keys():\n",
    "                self.a2[i][j] = {}\n",
    "            self.a2[i][j][k] = counter[key]/denom[i+'<sep>'+j]\n",
    "        \n",
    "    def fit(self, X:List[str]):\n",
    "        self.__pi(X)\n",
    "        self.__a(X)\n",
    "        self.__a2(X)\n",
    "        \n",
    "    def write(self):\n",
    "        first_token = np.random.choice(list(self.pi.keys()), p=list(self.pi.values()))\n",
    "        second_token = np.random.choice(list(self.a[first_token].keys()), p=list(self.a[first_token].values()))\n",
    "        sentence = [first_token, second_token]\n",
    "        while True:\n",
    "            penultimate, last = sentence[-2], sentence[-1]\n",
    "            next_probas = self.a2[penultimate][last]\n",
    "            next_token = np.random.choice(list(next_probas.keys()), p=list(next_probas.values()))\n",
    "            if next_token=='<eos>':\n",
    "                break\n",
    "            else:\n",
    "                sentence.append(next_token)\n",
    "        return ' '.join(sentence)\n",
    "            \n",
    "a = MarkovModel()\n",
    "a.fit(txt_frost)\n",
    "print(a.write())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9af07",
   "metadata": {
    "papermill": {
     "duration": 0.003055,
     "end_time": "2024-04-10T09:42:53.031581",
     "exception": false,
     "start_time": "2024-04-10T09:42:53.028526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'> Documentar classe;  Aula 41</p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4623586,
     "sourceId": 7878148,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.309255,
   "end_time": "2024-04-10T09:42:53.758905",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-10T09:42:47.449650",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
