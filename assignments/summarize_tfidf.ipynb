{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550bf63f-655b-436a-bd5a-ccab6856068f",
   "metadata": {},
   "source": [
    "# Text Summarization with TF-IDF\n",
    "* This lab is aimed at conceiving an  extractive summarization mechanism with the use of TF-IDF.\n",
    "* Given an article, we'll split its sentences and apply TF-IDF to them. Our extraction metric is going to be the me `np.nanmean` of the document's vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48be34c-0465-4582-9177-415177dd92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir data\n",
    "# !wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ed4846-2517-43c9-a7c1-c028e2cbb1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/bbc_text_cls.csv')\n",
    "df = df[df.labels=='business']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7081a932-2fea-4fbf-a0da-ce83c7a9a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from typing import List\n",
    "\n",
    "def get_sentences(df:pd.DataFrame, idx:int|None=None)->List[str]:\n",
    "    ''' \n",
    "        Extracts the sentences of a certain article from the dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `df`: `pd.DataFrame`\n",
    "            The news articles dataset.\n",
    "        `idx`: int\n",
    "            The index of the desired article. It will be randomly chosen if it is\n",
    "            set to None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A list with the article's sentences.\n",
    "    '''\n",
    "    if idx is None:\n",
    "        idx = np.random.randint(low=0, high=df.shape[0], size=1)[0]\n",
    "    text = df.iloc[idx, 0]\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c72089d2-ebf2-4474-ab6d-cfd49083b38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Home furnishings and furniture stores also performed well, rising 2.2%.',\n",
       " 'However, long-term claims slipped to their lowest level since 2001.',\n",
       " 'During that time, sales grew a lacklustre 2.9% in 2001 and 2.5% a year later.',\n",
       " '\"Consumers for now remain willing to spend freely, sustaining the US expansion.',\n",
       " 'The belief comes despite the latest labor department report showing a surprise rise in unemployment.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class ExtractiveSummarizer:\n",
    "    '''\n",
    "        A text-extraction based summarizer. It must return the p% most important \n",
    "        fragments of a document.\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        `p`: float\n",
    "            The desired top percentagem\n",
    "    '''\n",
    "    def __init__(self, p:float):\n",
    "        assert p>0 and p<1, '`p` must pertain to ]0,1[.'\n",
    "        self.p = p\n",
    "\n",
    "    def __compute_means(self)->np.ndarray:\n",
    "        '''\n",
    "            Computes the TF-IDF means for each provided document.\n",
    "        '''\n",
    "        _means = TfidfVectorizer().fit_transform(self._sentences).toarray()\n",
    "        return np.nanmean(np.where(_means==0, np.nan, _means), axis=1)\n",
    "\n",
    "    def fit(self, X:List[str]):\n",
    "        '''\n",
    "            Computes the average TF-IDF for each presenteed document.\n",
    "\n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[str]\n",
    "                A collection of sentences from a certain document.\n",
    "        '''\n",
    "        self._sentences = X\n",
    "        self._means = self.__compute_means()\n",
    "        return self\n",
    "\n",
    "    def transform(self)->List[str]:\n",
    "        '''\n",
    "            Returns the p% most important fragments of the provided text.\n",
    "        '''\n",
    "        amount_retrieve = int(round(self.p * len(self._sentences), 0))\n",
    "        idxs_retrieve = np.argsort(self._means)[-amount_retrieve:].tolist()\n",
    "        return [self._sentences[i] for i in reversed(idxs_retrieve)]\n",
    "\n",
    "sample_sentence = get_sentences(df, )\n",
    "ExtractiveSummarizer(.25).fit(sample_sentence).transform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
