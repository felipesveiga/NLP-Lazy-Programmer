{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d3efca",
   "metadata": {
    "papermill": {
     "duration": 0.005856,
     "end_time": "2024-03-21T20:15:44.711236",
     "exception": false,
     "start_time": "2024-03-21T20:15:44.705380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Poe x Frost \n",
    "* This project aims to conceive a classification strategy of differentiating Edgar Allan Poe's poems from Robert Frost's. We'll conduct the experiment by training two separate Markov Models, each of them calibrated with the poems of one of the poets.\n",
    "* Then, given the $p(\\text{text}|\\text{author})$ returned by the models, we'll apply the Bayes' Theorem to compute $p(\\text{author}|\\text{text})$ to receive the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebaab8",
   "metadata": {
    "papermill": {
     "duration": 0.005089,
     "end_time": "2024-03-21T20:15:44.722479",
     "exception": false,
     "start_time": "2024-03-21T20:15:44.717390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bab2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:44.735274Z",
     "iopub.status.busy": "2024-03-21T20:15:44.734814Z",
     "iopub.status.idle": "2024-03-21T20:15:44.768771Z",
     "shell.execute_reply": "2024-03-21T20:15:44.767393Z"
    },
    "papermill": {
     "duration": 0.044137,
     "end_time": "2024-03-21T20:15:44.771884",
     "exception": false,
     "start_time": "2024-03-21T20:15:44.727747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from typing import List\n",
    "\n",
    "def load_text(filename:str)->List[str]:\n",
    "    '''\n",
    "        Reads the .txt file.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        `filename`: str\n",
    "            The name of the poems file.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        A list containing each strophe's content.\n",
    "    '''\n",
    "    with open(f'/kaggle/input/poe-vs-frost/{filename}', 'r') as f:\n",
    "        strophe_delim = '\\n\\n'\n",
    "        return sub('\\n\\u2009\\n', strophe_delim, f.read()).split(strophe_delim)\n",
    "    \n",
    "txt_frost = load_text('05_robert_frost.txt')\n",
    "txt_poe = load_text('05_edgar_allan_poe.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54d078d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:44.785248Z",
     "iopub.status.busy": "2024-03-21T20:15:44.784834Z",
     "iopub.status.idle": "2024-03-21T20:15:44.789822Z",
     "shell.execute_reply": "2024-03-21T20:15:44.788908Z"
    },
    "papermill": {
     "duration": 0.014584,
     "end_time": "2024-03-21T20:15:44.792241",
     "exception": false,
     "start_time": "2024-03-21T20:15:44.777657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth; \n"
     ]
    }
   ],
   "source": [
    "# Note that the variables are lists of strophes content. \n",
    "print(txt_frost[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3276e",
   "metadata": {
    "papermill": {
     "duration": 0.005178,
     "end_time": "2024-03-21T20:15:44.803107",
     "exception": false,
     "start_time": "2024-03-21T20:15:44.797929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Datasets split\n",
    "* As in any Data Science project, we'll have to split our sets in two partitions. One dedicated to training our models and the other one to simply estimate the algorithm's performance in deployment scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34656c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:44.815808Z",
     "iopub.status.busy": "2024-03-21T20:15:44.815382Z",
     "iopub.status.idle": "2024-03-21T20:15:46.383862Z",
     "shell.execute_reply": "2024-03-21T20:15:46.382549Z"
    },
    "papermill": {
     "duration": 1.578022,
     "end_time": "2024-03-21T20:15:46.386560",
     "exception": false,
     "start_time": "2024-03-21T20:15:44.808538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_poe, test_poe = train_test_split(txt_poe, train_size=.75, random_state=42)\n",
    "train_frost, test_frost = train_test_split(txt_frost, train_size=.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a514869e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:46.400008Z",
     "iopub.status.busy": "2024-03-21T20:15:46.399475Z",
     "iopub.status.idle": "2024-03-21T20:15:46.407499Z",
     "shell.execute_reply": "2024-03-21T20:15:46.406436Z"
    },
    "papermill": {
     "duration": 0.017238,
     "end_time": "2024-03-21T20:15:46.409865",
     "exception": false,
     "start_time": "2024-03-21T20:15:46.392627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6460176991150443"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that we are dealing with an unbalanced dataset.\n",
    "len(txt_frost)/ (len(txt_poe)+len(txt_frost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd988d",
   "metadata": {
    "papermill": {
     "duration": 0.005141,
     "end_time": "2024-03-21T20:15:46.420521",
     "exception": false,
     "start_time": "2024-03-21T20:15:46.415380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fitting our Models\n",
    "* Let's use the class below in order to generate the $A$'s and $\\pi$'s of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ecab44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:46.433442Z",
     "iopub.status.busy": "2024-03-21T20:15:46.433002Z",
     "iopub.status.idle": "2024-03-21T20:15:48.209125Z",
     "shell.execute_reply": "2024-03-21T20:15:48.207617Z"
    },
    "papermill": {
     "duration": 1.78619,
     "end_time": "2024-03-21T20:15:48.212044",
     "exception": false,
     "start_time": "2024-03-21T20:15:46.425854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from typing import List\n",
    "\n",
    "class MarkovModel:\n",
    "    '''\n",
    "       Markov Model, with Add-Epsilon Smoothing.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        `corpus`: List[str]\n",
    "            List with the documents to be used.\n",
    "        `epsilon`: float\n",
    "            Smoothing degree of the probabilities.\n",
    "            \n",
    "        Methods\n",
    "        ------\n",
    "        `fit`: Generates the model's A and pi.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        `a`: `pd.DataFrame`\n",
    "            The model's A matrix.\n",
    "        `_a`: Dict[str, Dict[str, int]]\n",
    "            A Dictionary mapping the number of occurences a given state transition happened.\n",
    "        `pi`: `pd.Series`\n",
    "            The model's pi vector.\n",
    "        `_pi`: Dict[str, int]\n",
    "            A dictionary informing the amount of times a given token started a sentence.\n",
    "    '''\n",
    "    def __init__(self, corpus:List[str], epsilon:float):\n",
    "        self.corpus = self.split_corpus(corpus)\n",
    "        self.corpus_length = len(self.corpus)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    @staticmethod\n",
    "    def split_corpus(corpus:List[str])->List[List[str]]:\n",
    "        '''\n",
    "            Tokenizes the corpus' documents.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `corpus`: List[str]\n",
    "                A list with each of the corpus' documents.\n",
    "                \n",
    "            Returns\n",
    "            -------\n",
    "            A list of the documents tokens.\n",
    "        '''\n",
    "        return [word_tokenize(document.lower()) for document in corpus]\n",
    "    \n",
    "    def __vocab(self)->None:\n",
    "        '''\n",
    "            Extraction of all the corpus tokens.\n",
    "            \n",
    "            We create a set with all training tokens and another one disregarding the ones only used as first word of the strophes.\n",
    "        '''\n",
    "        self._vocab, self._a_vocab = [], []\n",
    "        \n",
    "        for doc in self.corpus:\n",
    "            self._vocab += doc\n",
    "            self._a_vocab+=doc[1:] # Not including the first tokens.\n",
    "            \n",
    "        self._vocab, self._a_vocab = set(self._vocab), set(self._a_vocab)        \n",
    "    \n",
    "    def __check_token(self, token:str)->str:\n",
    "        '''\n",
    "            Masks a token with '<UNKNOWN>' mark if it is not included in the training set.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `token`: str\n",
    "                The token under scrutiny\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            The treated token.\n",
    "        '''\n",
    "        return token if token in self._vocab else '<UNKNOWN>'\n",
    "    \n",
    "    def __pi(self):\n",
    "        '''\n",
    "            Encharged for measuring the model's pi vector.\n",
    "        '''\n",
    "        self._pi = {}\n",
    "        m = self.a.shape[0]\n",
    "        \n",
    "        for doc in self.corpus:\n",
    "            i = doc[0]\n",
    "            if i not in self._pi.keys():\n",
    "                self._pi[i] = 1\n",
    "            else:\n",
    "                self._pi[i]+=1\n",
    "        \n",
    "        self._pi['<UNKNOWN>'] = 0 # Defining a key for possible tokens of the test set that were unseen during training.\n",
    "        self.pi =  (pd.Series(self._pi)+self.epsilon) / (self.corpus_length+self.epsilon*m)\n",
    "        \n",
    "    def __a(self):\n",
    "        '''\n",
    "            Measures the model's A matrix.\n",
    "        '''\n",
    "        self._a = {j:{} for j in self._a_vocab}\n",
    "        for doc in self.corpus:\n",
    "            for idx, j in enumerate(doc[1:], start=1):\n",
    "                d_j = self._a[j]\n",
    "                i = doc[idx-1]\n",
    "                if i not in d_j.keys():\n",
    "                    d_j[i] = 1\n",
    "                else:\n",
    "                    d_j[i] += 1\n",
    "        self._a['<UNKNOWN>'] = {'<UNKNOWN>':0}\n",
    "        a = pd.DataFrame(self._a).fillna(0)\n",
    "        num = (a+self.epsilon)\n",
    "        denom = a.sum(axis=1, skipna=True)+a.shape[0]*self.epsilon\n",
    "        self.a =  num.div(denom, axis=0) \n",
    "        \n",
    "\n",
    "    def fit(self):\n",
    "        '''\n",
    "            Fits the algorithm to the provided corpus.\n",
    "        '''\n",
    "        self.__vocab()\n",
    "        self.__a()\n",
    "        self.__pi()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, text:str)->float:\n",
    "        text = word_tokenize(text.lower())\n",
    "        text = list(map(self.__check_token, text))\n",
    "        proba_pi = np.log(self.pi[text[0]])\n",
    "        proba_a = np.log([self.a.loc[text[i], text[i+1]] for i, _ in enumerate(text[:-1])])\n",
    "        return  proba_pi + np.sum(proba_a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90c9684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:48.225522Z",
     "iopub.status.busy": "2024-03-21T20:15:48.224695Z",
     "iopub.status.idle": "2024-03-21T20:15:49.191955Z",
     "shell.execute_reply": "2024-03-21T20:15:49.190958Z"
    },
    "papermill": {
     "duration": 0.976754,
     "end_time": "2024-03-21T20:15:49.194472",
     "exception": false,
     "start_time": "2024-03-21T20:15:48.217718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30.68026919760242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frost_model = MarkovModel(train_frost, 1)\n",
    "frost_model.fit()\n",
    "frost_model.predict('Obladi, eduardo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2fcd58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:49.208452Z",
     "iopub.status.busy": "2024-03-21T20:15:49.207316Z",
     "iopub.status.idle": "2024-03-21T20:15:49.214914Z",
     "shell.execute_reply": "2024-03-21T20:15:49.213710Z"
    },
    "papermill": {
     "duration": 0.017157,
     "end_time": "2024-03-21T20:15:49.217483",
     "exception": false,
     "start_time": "2024-03-21T20:15:49.200326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30.68026919760242"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frost_model.predict('Obladi, eduardo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83dbbac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:49.231510Z",
     "iopub.status.busy": "2024-03-21T20:15:49.231040Z",
     "iopub.status.idle": "2024-03-21T20:15:49.239385Z",
     "shell.execute_reply": "2024-03-21T20:15:49.238177Z"
    },
    "papermill": {
     "duration": 0.018217,
     "end_time": "2024-03-21T20:15:49.241865",
     "exception": false,
     "start_time": "2024-03-21T20:15:49.223648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21.127971658774452"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frost_model.predict('Hello, there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af663282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:15:49.256588Z",
     "iopub.status.busy": "2024-03-21T20:15:49.256185Z",
     "iopub.status.idle": "2024-03-21T20:15:49.264296Z",
     "shell.execute_reply": "2024-03-21T20:15:49.262995Z"
    },
    "papermill": {
     "duration": 0.018593,
     "end_time": "2024-03-21T20:15:49.266633",
     "exception": false,
     "start_time": "2024-03-21T20:15:49.248040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004510599909788002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frost_model.a.loc['a', 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69829e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T17:25:44.810198Z",
     "iopub.status.busy": "2024-03-18T17:25:44.809340Z",
     "iopub.status.idle": "2024-03-18T17:25:44.816991Z",
     "shell.execute_reply": "2024-03-18T17:25:44.815925Z",
     "shell.execute_reply.started": "2024-03-18T17:25:44.810156Z"
    },
    "papermill": {
     "duration": 0.006041,
     "end_time": "2024-03-21T20:15:49.279043",
     "exception": false,
     "start_time": "2024-03-21T20:15:49.273002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'> Documentar `predict` da classe; Treinar os modelos</p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4623586,
     "sourceId": 7878148,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.483508,
   "end_time": "2024-03-21T20:15:50.007889",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-21T20:15:41.524381",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
