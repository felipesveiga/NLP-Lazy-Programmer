{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7162555f",
   "metadata": {
    "papermill": {
     "duration": 0.005438,
     "end_time": "2024-03-22T10:02:03.816679",
     "exception": false,
     "start_time": "2024-03-22T10:02:03.811241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Poe x Frost \n",
    "* This project aims to conceive a classification strategy of differentiating Edgar Allan Poe's poems from Robert Frost's. We'll conduct the experiment by training two separate Markov Models, each of them calibrated with the poems of one of the poets.\n",
    "* Then, given the $p(\\text{text}|\\text{author})$ returned by the models, we'll apply the Bayes' Theorem to compute $p(\\text{author}|\\text{text})$ to receive the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd156f7",
   "metadata": {
    "papermill": {
     "duration": 0.004674,
     "end_time": "2024-03-22T10:02:03.826764",
     "exception": false,
     "start_time": "2024-03-22T10:02:03.822090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850b6895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T10:02:03.839356Z",
     "iopub.status.busy": "2024-03-22T10:02:03.838544Z",
     "iopub.status.idle": "2024-03-22T10:02:03.877878Z",
     "shell.execute_reply": "2024-03-22T10:02:03.876932Z"
    },
    "papermill": {
     "duration": 0.048808,
     "end_time": "2024-03-22T10:02:03.880659",
     "exception": false,
     "start_time": "2024-03-22T10:02:03.831851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from typing import List\n",
    "\n",
    "def load_text(filename:str)->List[str]:\n",
    "    '''\n",
    "        Reads the .txt file.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        `filename`: str\n",
    "            The name of the poems file.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        A list containing each strophe's content.\n",
    "    '''\n",
    "    with open(f'/kaggle/input/poe-vs-frost/{filename}', 'r') as f:\n",
    "        strophe_delim = '\\n\\n'\n",
    "        return sub('\\n\\u2009\\n', strophe_delim, f.read()).split(strophe_delim)\n",
    "    \n",
    "txt_frost = load_text('05_robert_frost.txt')\n",
    "txt_poe = load_text('05_edgar_allan_poe.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55929cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T10:02:03.893200Z",
     "iopub.status.busy": "2024-03-22T10:02:03.892417Z",
     "iopub.status.idle": "2024-03-22T10:02:03.898463Z",
     "shell.execute_reply": "2024-03-22T10:02:03.897352Z"
    },
    "papermill": {
     "duration": 0.015323,
     "end_time": "2024-03-22T10:02:03.901136",
     "exception": false,
     "start_time": "2024-03-22T10:02:03.885813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth; \n"
     ]
    }
   ],
   "source": [
    "# Note that the variables are lists of strophes content. \n",
    "print(txt_frost[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f006355",
   "metadata": {
    "papermill": {
     "duration": 0.004998,
     "end_time": "2024-03-22T10:02:03.911432",
     "exception": false,
     "start_time": "2024-03-22T10:02:03.906434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Datasets split\n",
    "* As in any Data Science project, we'll have to split our sets in two partitions. One dedicated to training our models and the other one to simply estimate the algorithm's performance in deployment scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2c7948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T10:02:03.924164Z",
     "iopub.status.busy": "2024-03-22T10:02:03.923357Z",
     "iopub.status.idle": "2024-03-22T10:02:05.442938Z",
     "shell.execute_reply": "2024-03-22T10:02:05.441597Z"
    },
    "papermill": {
     "duration": 1.529244,
     "end_time": "2024-03-22T10:02:05.445901",
     "exception": false,
     "start_time": "2024-03-22T10:02:03.916657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_poe, test_poe = train_test_split(txt_poe, train_size=.75, random_state=42)\n",
    "train_frost, test_frost = train_test_split(txt_frost, train_size=.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2dbfc33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T10:02:05.458067Z",
     "iopub.status.busy": "2024-03-22T10:02:05.457493Z",
     "iopub.status.idle": "2024-03-22T10:02:05.467004Z",
     "shell.execute_reply": "2024-03-22T10:02:05.465793Z"
    },
    "papermill": {
     "duration": 0.018193,
     "end_time": "2024-03-22T10:02:05.469353",
     "exception": false,
     "start_time": "2024-03-22T10:02:05.451160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6460176991150443"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that we are dealing with an unbalanced dataset.\n",
    "len(txt_frost)/ (len(txt_poe)+len(txt_frost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4860885c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T10:02:05.481586Z",
     "iopub.status.busy": "2024-03-22T10:02:05.481200Z",
     "iopub.status.idle": "2024-03-22T10:02:05.486705Z",
     "shell.execute_reply": "2024-03-22T10:02:05.485554Z"
    },
    "papermill": {
     "duration": 0.014551,
     "end_time": "2024-03-22T10:02:05.489155",
     "exception": false,
     "start_time": "2024-03-22T10:02:05.474604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's store each class' probability in a dictionary.\n",
    "proba_frost = len(txt_frost)/ (len(txt_poe)+len(txt_frost))\n",
    "probas = {'frost':proba_frost, 'poe':(1-proba_frost)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158ae77",
   "metadata": {
    "papermill": {
     "duration": 0.005133,
     "end_time": "2024-03-22T10:02:05.499683",
     "exception": false,
     "start_time": "2024-03-22T10:02:05.494550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fitting our Models\n",
    "* Let's use the class below in order to generate the $A$'s and $\\pi$'s of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdce002d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T10:02:05.511959Z",
     "iopub.status.busy": "2024-03-22T10:02:05.511571Z",
     "iopub.status.idle": "2024-03-22T10:02:07.180653Z",
     "shell.execute_reply": "2024-03-22T10:02:07.179467Z"
    },
    "papermill": {
     "duration": 1.67867,
     "end_time": "2024-03-22T10:02:07.183507",
     "exception": false,
     "start_time": "2024-03-22T10:02:05.504837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from typing import List\n",
    "\n",
    "class MarkovModel:\n",
    "    '''\n",
    "       Markov Model, with Add-Epsilon Smoothing.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        `corpus`: List[str]\n",
    "            List with the documents to be used.\n",
    "        `epsilon`: float\n",
    "            Smoothing degree of the probabilities.\n",
    "        `name`: str\n",
    "            A name for your model.\n",
    "            \n",
    "        Methods\n",
    "        ------\n",
    "        `fit`: Generates the model's A and pi.\n",
    "        `predict_log_proba`: Estimates the probability's log of a given sequence.\n",
    "        \n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        `a`: `pd.DataFrame`\n",
    "            The model's A matrix.\n",
    "        `_a`: Dict[str, Dict[str, int]]\n",
    "            A Dictionary mapping the number of occurences a given state transition happened.\n",
    "        `pi`: `pd.Series`\n",
    "            The model's pi vector.\n",
    "        `_pi`: Dict[str, int]\n",
    "            A dictionary informing the amount of times a given token started a sentence.\n",
    "        `_vocab`: Set[str]\n",
    "            A set object with all the corpus's vocabulary.\n",
    "    '''\n",
    "    def __init__(self, corpus:List[str], epsilon:float, name:str):\n",
    "        self.corpus = self.split_corpus(corpus)\n",
    "        self.corpus_length = len(self.corpus)\n",
    "        self.epsilon = epsilon\n",
    "        self.name = name\n",
    "\n",
    "    @staticmethod\n",
    "    def split_corpus(corpus:List[str])->List[List[str]]:\n",
    "        '''\n",
    "            Tokenizes the corpus' documents.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `corpus`: List[str]\n",
    "                A list with each of the corpus' documents.\n",
    "                \n",
    "            Returns\n",
    "            -------\n",
    "            A list of the documents tokens.\n",
    "        '''\n",
    "        return [word_tokenize(document.lower()) for document in corpus]\n",
    "    \n",
    "    def __vocab(self)->None:\n",
    "        '''\n",
    "            Extraction of all the corpus tokens.\n",
    "            \n",
    "            We create a set with all training tokens and another one disregarding the ones only used as first word of the strophes.\n",
    "        '''\n",
    "        self._vocab, self._a_vocab = [], []\n",
    "        \n",
    "        for doc in self.corpus:\n",
    "            self._vocab += doc\n",
    "            self._a_vocab+=doc[1:] # Not including the first tokens.\n",
    "            \n",
    "        self._vocab, self._a_vocab = set(self._vocab), set(self._a_vocab)        \n",
    "    \n",
    "    def __check_token(self, token:str)->str:\n",
    "        '''\n",
    "            Masks a token with '<UNKNOWN>' mark if it is not included in the training set.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `token`: str\n",
    "                The token under scrutiny\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            The treated token.\n",
    "        '''\n",
    "        return token if token in self._vocab else '<UNKNOWN>'\n",
    "    \n",
    "    def __pi(self):\n",
    "        '''\n",
    "            Encharged for measuring the model's pi vector.\n",
    "        '''\n",
    "        self._pi = {}\n",
    "        m = self.a.shape[0]\n",
    "        \n",
    "        for doc in self.corpus:\n",
    "            i = doc[0]\n",
    "            if i not in self._pi.keys():\n",
    "                self._pi[i] = 1\n",
    "            else:\n",
    "                self._pi[i]+=1\n",
    "        \n",
    "        self._pi['<UNKNOWN>'] = 0 # Defining a key for possible tokens of the test set that were unseen during training.\n",
    "        self.pi =  (pd.Series(self._pi)+self.epsilon) / (self.corpus_length+self.epsilon*m)\n",
    "        \n",
    "    def __a(self):\n",
    "        '''\n",
    "            Measures the model's A matrix.\n",
    "        '''\n",
    "        self._a = {j:{} for j in self._a_vocab}\n",
    "        for doc in self.corpus:\n",
    "            for idx, j in enumerate(doc[1:], start=1):\n",
    "                d_j = self._a[j]\n",
    "                i = doc[idx-1]\n",
    "                if i not in d_j.keys():\n",
    "                    d_j[i] = 1\n",
    "                else:\n",
    "                    d_j[i] += 1\n",
    "        self._a['<UNKNOWN>'] = {'<UNKNOWN>':0}\n",
    "        a = pd.DataFrame(self._a).fillna(0)\n",
    "        num = (a+self.epsilon)\n",
    "        denom = a.sum(axis=1, skipna=True)+a.shape[0]*self.epsilon\n",
    "        self.a =  num.div(denom, axis=0) \n",
    "        \n",
    "\n",
    "    def fit(self):\n",
    "        '''\n",
    "            Fits the algorithm to the provided corpus.\n",
    "        '''\n",
    "        self.__vocab()\n",
    "        self.__a()\n",
    "        self.__pi()\n",
    "        return self\n",
    "    \n",
    "    def predict_log_proba(self, text:str)->float:\n",
    "        '''\n",
    "            Estimates the probability's log of a given sequence.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `text`: str\n",
    "                The text whose probability needs to be computed.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            The sequence's log probability.\n",
    "        '''\n",
    "        text = word_tokenize(text.lower())\n",
    "        text = list(map(self.__check_token, text))\n",
    "        proba_pi = np.log(self.pi[text[0]])\n",
    "        proba_a = np.log([self.a.loc[text[i], text[i+1]] for i, _ in enumerate(text[:-1])])\n",
    "        return  proba_pi + np.sum(proba_a) \n",
    "    \n",
    "    def predict_proba(self, text:str)->float:\n",
    "        '''\n",
    "            Estimates the probability of a given sequence.\n",
    "            \n",
    "            *Note:* There is a risk of the output to be 0 for long sequences.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `text`: str\n",
    "                The text whose probability needs to be computed.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            The sequence's probability.\n",
    "        '''\n",
    "        return np.exp(self.predict_log_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be49d1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T10:02:07.196057Z",
     "iopub.status.busy": "2024-03-22T10:02:07.195519Z",
     "iopub.status.idle": "2024-03-22T10:02:08.491097Z",
     "shell.execute_reply": "2024-03-22T10:02:08.489728Z"
    },
    "papermill": {
     "duration": 1.305104,
     "end_time": "2024-03-22T10:02:08.493960",
     "exception": false,
     "start_time": "2024-03-22T10:02:07.188856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally fitting our Markov Models.\n",
    "model_frost = MarkovModel(train_frost, 1, 'frost').fit()\n",
    "model_poe = MarkovModel(train_poe, 1, 'poe').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a573902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T10:02:08.508666Z",
     "iopub.status.busy": "2024-03-22T10:02:08.508254Z",
     "iopub.status.idle": "2024-03-22T10:02:08.513601Z",
     "shell.execute_reply": "2024-03-22T10:02:08.512357Z"
    },
    "papermill": {
     "duration": 0.015756,
     "end_time": "2024-03-22T10:02:08.516296",
     "exception": false,
     "start_time": "2024-03-22T10:02:08.500540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_author(model_frost:MarkovModel, model_poe:MarkovModel):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd6d95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T17:25:44.810198Z",
     "iopub.status.busy": "2024-03-18T17:25:44.809340Z",
     "iopub.status.idle": "2024-03-18T17:25:44.816991Z",
     "shell.execute_reply": "2024-03-18T17:25:44.815925Z",
     "shell.execute_reply.started": "2024-03-18T17:25:44.810156Z"
    },
    "papermill": {
     "duration": 0.005118,
     "end_time": "2024-03-22T10:02:08.526926",
     "exception": false,
     "start_time": "2024-03-22T10:02:08.521808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'> Fazer a `predict_author`; Usar probabilidades-log, assim como est√° na aula 35 (7:15)</p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4623586,
     "sourceId": 7878148,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.573609,
   "end_time": "2024-03-22T10:02:09.255464",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-22T10:02:00.681855",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
