{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064fc249",
   "metadata": {
    "papermill": {
     "duration": 0.004393,
     "end_time": "2024-04-17T18:04:51.639479",
     "exception": false,
     "start_time": "2024-04-17T18:04:51.635086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BBC Articles Spinner\n",
    "* This is a small NLP project target on using Markov Models in building article spinner applications.\n",
    "* Here, we'll be dealing with a BBC News corpus containing business texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e865072c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:04:51.650451Z",
     "iopub.status.busy": "2024-04-17T18:04:51.649438Z",
     "iopub.status.idle": "2024-04-17T18:04:52.841467Z",
     "shell.execute_reply": "2024-04-17T18:04:52.840236Z"
    },
    "papermill": {
     "duration": 1.20078,
     "end_time": "2024-04-17T18:04:52.844305",
     "exception": false,
     "start_time": "2024-04-17T18:04:51.643525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1    Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2    Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3    High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4    Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our corpus.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = pd.read_csv('/kaggle/input/bbc-business/06_bbc_text_cls.csv')\n",
    "corpus = corpus[corpus.labels=='business']['text'] # As mentioned, we'll be just focusing in business articles.\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd750a5",
   "metadata": {
    "papermill": {
     "duration": 0.003655,
     "end_time": "2024-04-17T18:04:52.852198",
     "exception": false,
     "start_time": "2024-04-17T18:04:52.848543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Treatment\n",
    "* Now, we must apply some transformations that are going to optimize the model's learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d19ec24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:04:52.862683Z",
     "iopub.status.busy": "2024-04-17T18:04:52.861155Z",
     "iopub.status.idle": "2024-04-17T18:04:57.818060Z",
     "shell.execute_reply": "2024-04-17T18:04:57.816805Z"
    },
    "papermill": {
     "duration": 4.965459,
     "end_time": "2024-04-17T18:04:57.821336",
     "exception": false,
     "start_time": "2024-04-17T18:04:52.855877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from typing import List\n",
    "\n",
    "def separate_paragraphs(s:str)->List[List[str]]:\n",
    "    '''\n",
    "        Turns a given string into list of tokens per paragraph.\n",
    "        \n",
    "        Note: It already lowercases the text.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        s: str\n",
    "            The provided text\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        An array mentioning the tokens from each of the string's paragraphs.\n",
    "    '''\n",
    "    paragraphs = s.split('\\n\\n') \n",
    "    return list(map(word_tokenize, paragraphs))\n",
    "     \n",
    "\n",
    "def treat(series:pd.Series)->List[List[str]]:\n",
    "    '''\n",
    "        Treats the corpus looking for better model fitting.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        series: `pd.Series`\n",
    "            A series contaning our documents.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        The treated texts ready for model consumption.\n",
    "    '''\n",
    "    series = map(str.lower, series)\n",
    "    return list(map(separate_paragraphs, series))\n",
    "\n",
    "# Applying the transformations to our news corpus. \n",
    "corpus = treat(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e153db",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-17T18:04:57.832062Z",
     "iopub.status.busy": "2024-04-17T18:04:57.831599Z",
     "iopub.status.idle": "2024-04-17T18:04:57.873455Z",
     "shell.execute_reply": "2024-04-17T18:04:57.871930Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.050798,
     "end_time": "2024-04-17T18:04:57.876571",
     "exception": false,
     "start_time": "2024-04-17T18:04:57.825773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: 0.37254901960784315,\n",
       " 28: 0.08431372549019608,\n",
       " 63: 0.03725490196078431,\n",
       " 127: 0.021568627450980392,\n",
       " 140: 0.013725490196078431,\n",
       " 126: 0.0196078431372549,\n",
       " 5: 0.34509803921568627,\n",
       " 29: 0.07254901960784314,\n",
       " 168: 0.011764705882352941,\n",
       " 231: 0.0058823529411764705,\n",
       " 154: 0.00784313725490196,\n",
       " 105: 0.027450980392156862,\n",
       " 7: 0.16470588235294117,\n",
       " 15: 0.011764705882352941,\n",
       " 81: 0.03333333333333333,\n",
       " 20: 0.0784313725490196,\n",
       " 186: 0.00980392156862745,\n",
       " 163: 0.0058823529411764705,\n",
       " 210: 0.00784313725490196,\n",
       " 4: 0.09019607843137255,\n",
       " 21: 0.0784313725490196,\n",
       " 60: 0.0196078431372549,\n",
       " 128: 0.00980392156862745,\n",
       " 27: 0.10392156862745099,\n",
       " 146: 0.03137254901960784,\n",
       " 120: 0.027450980392156862,\n",
       " 25: 0.10392156862745099,\n",
       " 61: 0.047058823529411764,\n",
       " 279: 0.00196078431372549,\n",
       " 33: 0.01764705882352941,\n",
       " 54: 0.00392156862745098,\n",
       " 51: 0.01568627450980392,\n",
       " 122: 0.023529411764705882,\n",
       " 99: 0.011764705882352941,\n",
       " 121: 0.025490196078431372,\n",
       " 23: 0.09607843137254903,\n",
       " 79: 0.021568627450980392,\n",
       " 108: 0.021568627450980392,\n",
       " 18: 0.047058823529411764,\n",
       " 83: 0.0196078431372549,\n",
       " 244: 0.00196078431372549,\n",
       " 86: 0.023529411764705882,\n",
       " 218: 0.0058823529411764705,\n",
       " 19: 0.049019607843137254,\n",
       " 17: 0.047058823529411764,\n",
       " 115: 0.0196078431372549,\n",
       " 50: 0.011764705882352941,\n",
       " 64: 0.050980392156862744,\n",
       " 145: 0.0196078431372549,\n",
       " 125: 0.025490196078431372,\n",
       " 82: 0.03333333333333333,\n",
       " 129: 0.0196078431372549,\n",
       " 58: 0.03529411764705882,\n",
       " 165: 0.00980392156862745,\n",
       " 85: 0.023529411764705882,\n",
       " 249: 0.00392156862745098,\n",
       " 26: 0.10784313725490197,\n",
       " 110: 0.021568627450980392,\n",
       " 107: 0.0196078431372549,\n",
       " 76: 0.01568627450980392,\n",
       " 147: 0.013725490196078431,\n",
       " 138: 0.03333333333333333,\n",
       " 184: 0.011764705882352941,\n",
       " 74: 0.025490196078431372,\n",
       " 175: 0.01568627450980392,\n",
       " 151: 0.00980392156862745,\n",
       " 114: 0.027450980392156862,\n",
       " 8: 0.021568627450980392,\n",
       " 139: 0.0196078431372549,\n",
       " 216: 0.00392156862745098,\n",
       " 153: 0.011764705882352941,\n",
       " 170: 0.00980392156862745,\n",
       " 30: 0.050980392156862744,\n",
       " 24: 0.07254901960784314,\n",
       " 109: 0.025490196078431372,\n",
       " 56: 0.021568627450980392,\n",
       " 183: 0.011764705882352941,\n",
       " 69: 0.029411764705882353,\n",
       " 41: 0.00980392156862745,\n",
       " 143: 0.01764705882352941,\n",
       " 68: 0.03137254901960784,\n",
       " 222: 0.00392156862745098,\n",
       " 66: 0.0392156862745098,\n",
       " 47: 0.01568627450980392,\n",
       " 101: 0.023529411764705882,\n",
       " 65: 0.03529411764705882,\n",
       " 141: 0.00784313725490196,\n",
       " 62: 0.021568627450980392,\n",
       " 67: 0.027450980392156862,\n",
       " 73: 0.023529411764705882,\n",
       " 98: 0.0196078431372549,\n",
       " 89: 0.01568627450980392,\n",
       " 225: 0.00392156862745098,\n",
       " 46: 0.01568627450980392,\n",
       " 106: 0.0196078431372549,\n",
       " 94: 0.021568627450980392,\n",
       " 91: 0.027450980392156862,\n",
       " 102: 0.013725490196078431,\n",
       " 124: 0.025490196078431372,\n",
       " 31: 0.043137254901960784,\n",
       " 200: 0.00392156862745098,\n",
       " 241: 0.00392156862745098,\n",
       " 174: 0.0196078431372549,\n",
       " 201: 0.0058823529411764705,\n",
       " 88: 0.00784313725490196,\n",
       " 70: 0.01568627450980392,\n",
       " 144: 0.011764705882352941,\n",
       " 80: 0.023529411764705882,\n",
       " 22: 0.0803921568627451,\n",
       " 123: 0.01568627450980392,\n",
       " 136: 0.025490196078431372,\n",
       " 103: 0.01568627450980392,\n",
       " 96: 0.021568627450980392,\n",
       " 49: 0.0058823529411764705,\n",
       " 113: 0.021568627450980392,\n",
       " 177: 0.00784313725490196,\n",
       " 32: 0.03529411764705882,\n",
       " 90: 0.01764705882352941,\n",
       " 148: 0.029411764705882353,\n",
       " 55: 0.023529411764705882,\n",
       " 111: 0.01764705882352941,\n",
       " 104: 0.021568627450980392,\n",
       " 77: 0.021568627450980392,\n",
       " 171: 0.00784313725490196,\n",
       " 164: 0.01764705882352941,\n",
       " 134: 0.013725490196078431,\n",
       " 72: 0.03529411764705882,\n",
       " 119: 0.021568627450980392,\n",
       " 152: 0.00980392156862745,\n",
       " 92: 0.01568627450980392,\n",
       " 158: 0.013725490196078431,\n",
       " 37: 0.01568627450980392,\n",
       " 16: 0.025490196078431372,\n",
       " 75: 0.011764705882352941,\n",
       " 133: 0.013725490196078431,\n",
       " 52: 0.013725490196078431,\n",
       " 84: 0.0196078431372549,\n",
       " 95: 0.011764705882352941,\n",
       " 34: 0.023529411764705882,\n",
       " 118: 0.011764705882352941,\n",
       " 59: 0.027450980392156862,\n",
       " 93: 0.021568627450980392,\n",
       " 187: 0.00980392156862745,\n",
       " 156: 0.00784313725490196,\n",
       " 131: 0.01568627450980392,\n",
       " 13: 0.0058823529411764705,\n",
       " 172: 0.0058823529411764705,\n",
       " 292: 0.00196078431372549,\n",
       " 159: 0.01568627450980392,\n",
       " 132: 0.021568627450980392,\n",
       " 149: 0.01764705882352941,\n",
       " 188: 0.0058823529411764705,\n",
       " 189: 0.00392156862745098,\n",
       " 130: 0.023529411764705882,\n",
       " 166: 0.013725490196078431,\n",
       " 135: 0.023529411764705882,\n",
       " 40: 0.013725490196078431,\n",
       " 97: 0.01568627450980392,\n",
       " 9: 0.00392156862745098,\n",
       " 192: 0.0058823529411764705,\n",
       " 212: 0.0058823529411764705,\n",
       " 344: 0.00196078431372549,\n",
       " 197: 0.00784313725490196,\n",
       " 53: 0.011764705882352941,\n",
       " 185: 0.0058823529411764705,\n",
       " 42: 0.00784313725490196,\n",
       " 229: 0.0058823529411764705,\n",
       " 196: 0.00784313725490196,\n",
       " 116: 0.03333333333333333,\n",
       " 35: 0.01568627450980392,\n",
       " 203: 0.0058823529411764705,\n",
       " 43: 0.013725490196078431,\n",
       " 112: 0.023529411764705882,\n",
       " 39: 0.00784313725490196,\n",
       " 45: 0.013725490196078431,\n",
       " 137: 0.027450980392156862,\n",
       " 160: 0.01568627450980392,\n",
       " 228: 0.00392156862745098,\n",
       " 181: 0.00392156862745098,\n",
       " 199: 0.00784313725490196,\n",
       " 248: 0.00196078431372549,\n",
       " 230: 0.0058823529411764705,\n",
       " 57: 0.0196078431372549,\n",
       " 48: 0.00784313725490196,\n",
       " 169: 0.011764705882352941,\n",
       " 182: 0.0196078431372549,\n",
       " 236: 0.0058823529411764705,\n",
       " 142: 0.011764705882352941,\n",
       " 150: 0.01568627450980392,\n",
       " 264: 0.00196078431372549,\n",
       " 237: 0.0058823529411764705,\n",
       " 71: 0.027450980392156862,\n",
       " 206: 0.00392156862745098,\n",
       " 117: 0.01568627450980392,\n",
       " 44: 0.00392156862745098,\n",
       " 36: 0.00784313725490196,\n",
       " 157: 0.00784313725490196,\n",
       " 193: 0.00784313725490196,\n",
       " 162: 0.00980392156862745,\n",
       " 155: 0.0196078431372549,\n",
       " 38: 0.029411764705882353,\n",
       " 215: 0.00196078431372549,\n",
       " 78: 0.011764705882352941,\n",
       " 179: 0.0058823529411764705,\n",
       " 195: 0.0058823529411764705,\n",
       " 10: 0.00784313725490196,\n",
       " 176: 0.011764705882352941,\n",
       " 226: 0.00392156862745098,\n",
       " 167: 0.0058823529411764705,\n",
       " 161: 0.00392156862745098,\n",
       " 214: 0.00196078431372549,\n",
       " 242: 0.00196078431372549,\n",
       " 207: 0.00784313725490196,\n",
       " 234: 0.00392156862745098,\n",
       " 208: 0.00392156862745098,\n",
       " 178: 0.00784313725490196,\n",
       " 238: 0.00392156862745098,\n",
       " 0: 0.0058823529411764705,\n",
       " 247: 0.00392156862745098,\n",
       " 281: 0.00196078431372549,\n",
       " 194: 0.00392156862745098,\n",
       " 100: 0.01568627450980392,\n",
       " 12: 0.0058823529411764705,\n",
       " 87: 0.00784313725490196,\n",
       " 276: 0.00196078431372549,\n",
       " 14: 0.00392156862745098,\n",
       " 204: 0.00784313725490196,\n",
       " 213: 0.00784313725490196,\n",
       " 246: 0.00196078431372549,\n",
       " 262: 0.00196078431372549,\n",
       " 243: 0.00392156862745098,\n",
       " 227: 0.0058823529411764705,\n",
       " 209: 0.0058823529411764705,\n",
       " 221: 0.00392156862745098,\n",
       " 270: 0.00392156862745098,\n",
       " 173: 0.00196078431372549,\n",
       " 198: 0.0058823529411764705,\n",
       " 269: 0.00196078431372549,\n",
       " 3: 0.00392156862745098,\n",
       " 190: 0.00392156862745098,\n",
       " 263: 0.00392156862745098,\n",
       " 202: 0.00196078431372549,\n",
       " 220: 0.00196078431372549,\n",
       " 180: 0.00196078431372549}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "class MarkovModel:\n",
    "    '''\n",
    "        A Second-Order Markov Model designed for writing poems.\n",
    "        \n",
    "        Method\n",
    "        ------\n",
    "        `fit`: It fits the model's probability distributions  according to a provided list of texts tokens.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        `pi`: A storage for first token probabilities.\n",
    "        `a`: The first order transition matrix for second token probabilities.\n",
    "        `a2`: The second order transition matrix\n",
    "    '''\n",
    "    def __pi(self, X:List[List[str]]):\n",
    "        '''\n",
    "            Builds the model's pi vector.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[List[str]]\n",
    "        '''\n",
    "        self.pi = Counter(len(p) for x in X for p in x)\n",
    "        self.pi = {token:count/len(X) for token, count in self.pi.items()}\n",
    "        \n",
    "    def __a(self, X:List[List[str]]):\n",
    "        '''\n",
    "            Builds the first order transition matrix.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[List[str]]\n",
    "        '''\n",
    "        counter = Counter(x[0]+'<sep>'+x[1] for x in X) \n",
    "        denom = Counter(x[0] for x in X)\n",
    "        self.a = {}\n",
    "        for key in counter.keys():\n",
    "            i,j = key.split('<sep>')\n",
    "            if i not in self.a.keys():\n",
    "                self.a[i] = {}\n",
    "            self.a[i][j] = counter[key]/denom[i]\n",
    "        \n",
    "            \n",
    "    def __a2(self, X:List[List[str]]):\n",
    "        '''\n",
    "            Builds the second order transition matrix.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[List[str]]\n",
    "        '''\n",
    "        counter = Counter(x[i-2]+'<sep>'+x[i-1]+'<sep>'+x[i] for x in X for i in range(2, len(x)))\n",
    "        denom = Counter(x[i-1]+'<sep>'+x[i] for x in X for i in range(1, len(x)-1))\n",
    "        self.a2 = {}\n",
    "        for key in counter.keys():\n",
    "            i,j,k = key.split('<sep>')\n",
    "            if i not in self.a2.keys():\n",
    "                self.a2[i] = {}\n",
    "            if j not in self.a2[i].keys():\n",
    "                self.a2[i][j] = {}\n",
    "            self.a2[i][j][k] = counter[key]/denom[i+'<sep>'+j]\n",
    "        \n",
    "    def fit(self, X:List[List[str]]):\n",
    "        '''\n",
    "            Constructs the model's vector and state transition matrices.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[List[str]]\n",
    "        '''\n",
    "        self.__pi(X)\n",
    "#         self.__a(X)\n",
    "#         self.__a2(X)\n",
    "        \n",
    "    def write(self):\n",
    "        '''\n",
    "            Writes a poem\n",
    "        '''\n",
    "        first_token = np.random.choice(list(self.pi.keys()), p=list(self.pi.values()))\n",
    "        second_token = np.random.choice(list(self.a[first_token].keys()), p=list(self.a[first_token].values()))\n",
    "        sentence = [first_token, second_token]\n",
    "        while True:\n",
    "            penultimate, last = sentence[-2], sentence[-1]\n",
    "            next_probas = self.a2[penultimate][last]\n",
    "            next_token = np.random.choice(list(next_probas.keys()), p=list(next_probas.values()))\n",
    "            if next_token=='<eos>':\n",
    "                break\n",
    "            else:\n",
    "                sentence.append(next_token)\n",
    "        return ' '.join(sentence)\n",
    "            \n",
    "model = MarkovModel()\n",
    "model.fit(corpus)\n",
    "model.pi\n",
    "# model.fit(corpus[0])\n",
    "# print(model.write())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a13f8d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:04:57.888309Z",
     "iopub.status.busy": "2024-04-17T18:04:57.887300Z",
     "iopub.status.idle": "2024-04-17T18:04:57.900855Z",
     "shell.execute_reply": "2024-04-17T18:04:57.898938Z"
    },
    "papermill": {
     "duration": 0.022676,
     "end_time": "2024-04-17T18:04:57.903753",
     "exception": false,
     "start_time": "2024-04-17T18:04:57.881077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ad', 'quarterly', 'the', 'time', 'time']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for text in corpus:\n",
    "    for p in text:\n",
    "        try:\n",
    "            a.append(p[0])\n",
    "        except:\n",
    "            print(p)\n",
    "a[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebab29",
   "metadata": {
    "papermill": {
     "duration": 0.004349,
     "end_time": "2024-04-17T18:04:57.912824",
     "exception": false,
     "start_time": "2024-04-17T18:04:57.908475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'>Existem parágrafos vazios que estão atrapalhando a construção do pi. </p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4804690,
     "sourceId": 8129202,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.22099,
   "end_time": "2024-04-17T18:04:58.641824",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T18:04:48.420834",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
