{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187b159b",
   "metadata": {
    "papermill": {
     "duration": 0.002749,
     "end_time": "2024-04-22T21:00:08.042641",
     "exception": false,
     "start_time": "2024-04-22T21:00:08.039892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BBC Articles Spinner\n",
    "* This is a small NLP project target on using Markov Models in building article spinner applications.\n",
    "* Here, we'll be dealing with a BBC News corpus containing business texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbefb28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T21:00:08.049793Z",
     "iopub.status.busy": "2024-04-22T21:00:08.049333Z",
     "iopub.status.idle": "2024-04-22T21:00:09.268352Z",
     "shell.execute_reply": "2024-04-22T21:00:09.267171Z"
    },
    "papermill": {
     "duration": 1.226107,
     "end_time": "2024-04-22T21:00:09.271580",
     "exception": false,
     "start_time": "2024-04-22T21:00:08.045473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1    Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2    Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3    High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4    Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our corpus.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = pd.read_csv('/kaggle/input/bbc-business/06_bbc_text_cls.csv')\n",
    "corpus = corpus[corpus.labels=='business']['text'] # As mentioned, we'll be just focusing in business articles.\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4115013",
   "metadata": {
    "papermill": {
     "duration": 0.002348,
     "end_time": "2024-04-22T21:00:09.276709",
     "exception": false,
     "start_time": "2024-04-22T21:00:09.274361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Treatment\n",
    "* Now, we must apply some transformations that are going to optimize the model's learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48fb560f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T21:00:09.285094Z",
     "iopub.status.busy": "2024-04-22T21:00:09.284649Z",
     "iopub.status.idle": "2024-04-22T21:00:13.272838Z",
     "shell.execute_reply": "2024-04-22T21:00:13.271494Z"
    },
    "papermill": {
     "duration": 3.9965,
     "end_time": "2024-04-22T21:00:13.275811",
     "exception": false,
     "start_time": "2024-04-22T21:00:09.279311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from typing import List\n",
    "\n",
    "def separate_paragraphs(s:str)->List[List[List[str]]]:\n",
    "    '''\n",
    "        Turns a given string into list of tokens per paragraph.\n",
    "        \n",
    "        Note: It already lowercases the text.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        s: str\n",
    "            The provided text\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        An array mentioning the tokens from each of the string's paragraphs.\n",
    "    '''\n",
    "    paragraphs = s.split('\\n\\n') \n",
    "    paragraphs = [p for p in paragraphs if len(p)>0] # Filtering out problematic paragraphs that contain no tokens (possibly because of\n",
    "    return list(map(word_tokenize, paragraphs))      # the use of two consecutive '\\n\\n's)\n",
    "     \n",
    "\n",
    "def treat(series:pd.Series)->List[List[List[str]]]:\n",
    "    '''\n",
    "        Treats the corpus looking for better model fitting.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        series: `pd.Series`\n",
    "            A series contaning our documents.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        The treated texts ready for model consumption.\n",
    "    '''\n",
    "    series = map(str.lower, series)\n",
    "    return list(map(separate_paragraphs, series))\n",
    "\n",
    "# Applying the transformations to our news corpus. \n",
    "corpus = treat(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a5be2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T21:00:13.283474Z",
     "iopub.status.busy": "2024-04-22T21:00:13.283081Z",
     "iopub.status.idle": "2024-04-22T21:00:13.971607Z",
     "shell.execute_reply": "2024-04-22T21:00:13.970462Z"
    },
    "papermill": {
     "duration": 0.695956,
     "end_time": "2024-04-22T21:00:13.974372",
     "exception": false,
     "start_time": "2024-04-22T21:00:13.278416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rank 'set to write off film 'ray '\\n\\nleisure group rank could unveil plans to extend its film services unit and sell its media business,reports claim.\\n\\nrank,formerly famous for the carry on series,will expose the shake-up at the announcement of its results on friday,the sunday telegraph reported . advisors goldman sachs are understood to have valued its demerged deluxe film unit at £300m,the report added . speculation of a possible shake-up has mounted since rank announced a study into a possible demerger in september . since mike smith's appointment as chief executive in 1999,the group has focused on fewer businesses and embarked on a major cost-cutting programme which has seen it dispose of a number of businesses,including the odeon cinema chain and the pinewood studios . the move to the group with three core divisions:gaming,hard rock and deluxe films,which provides technical services to hollywood studios.\\n\\nrank now aims to concentrate on its gaming,bars and hotels business,including extending its hard rock brand to its casinos - trials of which have been a success . it also owns deluxe media,which makes and distributes dvds and videos . however,that business is seen as less successful . last year it made profits of £21.5m on a turnover of £392.1m and experts suggest its success in moving to dvds from vhs video could make it an attractive target for a private equity buyer . a spokesman for the firm refused to comment on the reports,but said any results from the demerger study were likely to be set out when it unveiled its results on friday . analysts predict the firm is likely to report a slight drop in annual pre-tax profits to £170m from £194m last year . formed in the 1940s the firm was a leading uk film producer and cinema owner for many years . it has now diversified into a range of other leisure activities - mainly in the uk - including hotels,roadside service areas and holiday centres . it now owns 34 grosvenor casinos,the mecca bingo chain and more than 100 hard rock cafes in 38 countries.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from typing import List\n",
    "\n",
    "class MarkovModel:\n",
    "    '''\n",
    "        A Second-Order Markov Model designed for performing article spinning.\n",
    "        \n",
    "        Method\n",
    "        ------\n",
    "        `fit`: It fits the model's probability distributions according to a provided list of paragraphs tokens from a myriad of texts.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        `a2`: The second order transition matrix\n",
    "    '''\n",
    "        \n",
    "            \n",
    "    def __a2(self, X:List[List[List[str]]]):\n",
    "        '''\n",
    "            Builds the second order transition matrix.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[List[str]]\n",
    "                The collection of texts as lists of tokens from each paragraph.\n",
    "        '''\n",
    "        counter = Counter(p[i-1]+'<sep>'+p[i+1]+'<sep>'+p[i] for x in X for p in x for i in range(1, len(p)-1))\n",
    "        denom = Counter(p[i-1]+'<sep>'+p[i+1] for x in X for p in x for i in range(1, len(p)-1))\n",
    "        self.a2 = {}\n",
    "        for key in counter.keys():\n",
    "            i,k,j = key.split('<sep>')\n",
    "            if i not in self.a2.keys():\n",
    "                self.a2[i] = {}\n",
    "            if k not in self.a2[i].keys():\n",
    "                self.a2[i][k] = {}\n",
    "            self.a2[i][k][j] = counter[key]/denom[i+'<sep>'+k]\n",
    "        \n",
    "    def fit(self, X:List[List[List[str]]]):\n",
    "        '''\n",
    "            Constructs the model's vector and state transition matrices.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[List[List[str]]]\n",
    "                The collection of texts as lists of tokens from each paragraph.\n",
    "        '''\n",
    "        self.__a2(X)\n",
    "        \n",
    "    def spin(self, X:List[List[str]], tokens_per_paragraph:int=2):\n",
    "        '''\n",
    "            Performs the Article Spinning\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            `X`: List[List[str]]\n",
    "                An instance of text tokens segregated by paragraphs.\n",
    "            `tokens_per_paragraph`: int, defaults to 2\n",
    "                The amount of tokens to spin.\n",
    "                \n",
    "            Returns\n",
    "            -------\n",
    "            The spinned article.\n",
    "        '''\n",
    "        X = X.copy()\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        for idx, p in enumerate(X):\n",
    "            to_remove_idxs = np.random.choice([i for i in range(1, len(p)-1)], size=tokens_per_paragraph, replace=False)\n",
    "            idx_token = {i:None for i in to_remove_idxs}\n",
    "            for idx_ in to_remove_idxs:\n",
    "                tokens_probas = self.a2[p[idx_-1]][p[idx_+1]]\n",
    "                idx_token[idx_] = np.random.choice(list(tokens_probas.keys()), p=list(tokens_probas.values()), size=1)[0]\n",
    "            for idx_ in idx_token:\n",
    "                X[idx][idx_] = idx_token[idx_]\n",
    "        return '\\n\\n'.join([detokenizer.detokenize(p) for p in X])\n",
    "\n",
    "            \n",
    "model = MarkovModel()\n",
    "model.fit(corpus)\n",
    "model.spin(corpus[20], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4804690,
     "sourceId": 8129202,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.78899,
   "end_time": "2024-04-22T21:00:14.699109",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-22T21:00:04.910119",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
