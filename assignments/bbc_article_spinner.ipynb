{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd10142",
   "metadata": {
    "papermill": {
     "duration": 0.003236,
     "end_time": "2024-04-18T22:22:40.522633",
     "exception": false,
     "start_time": "2024-04-18T22:22:40.519397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BBC Articles Spinner\n",
    "* This is a small NLP project target on using Markov Models in building article spinner applications.\n",
    "* Here, we'll be dealing with a BBC News corpus containing business texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9caa14a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T22:22:40.530420Z",
     "iopub.status.busy": "2024-04-18T22:22:40.529732Z",
     "iopub.status.idle": "2024-04-18T22:22:41.613280Z",
     "shell.execute_reply": "2024-04-18T22:22:41.612416Z"
    },
    "papermill": {
     "duration": 1.090092,
     "end_time": "2024-04-18T22:22:41.615410",
     "exception": false,
     "start_time": "2024-04-18T22:22:40.525318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1    Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2    Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3    High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4    Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our corpus.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = pd.read_csv('/kaggle/input/bbc-business/06_bbc_text_cls.csv')\n",
    "corpus = corpus[corpus.labels=='business']['text'] # As mentioned, we'll be just focusing in business articles.\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e904ca2",
   "metadata": {
    "papermill": {
     "duration": 0.00251,
     "end_time": "2024-04-18T22:22:41.620852",
     "exception": false,
     "start_time": "2024-04-18T22:22:41.618342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Treatment\n",
    "* Now, we must apply some transformations that are going to optimize the model's learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a55dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T22:22:41.628411Z",
     "iopub.status.busy": "2024-04-18T22:22:41.627745Z",
     "iopub.status.idle": "2024-04-18T22:22:45.212316Z",
     "shell.execute_reply": "2024-04-18T22:22:45.210956Z"
    },
    "papermill": {
     "duration": 3.591659,
     "end_time": "2024-04-18T22:22:45.215133",
     "exception": false,
     "start_time": "2024-04-18T22:22:41.623474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from typing import List\n",
    "\n",
    "def separate_paragraphs(s:str)->List[List[str]]:\n",
    "    '''\n",
    "        Turns a given string into list of tokens per paragraph.\n",
    "        \n",
    "        Note: It already lowercases the text.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        s: str\n",
    "            The provided text\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        An array mentioning the tokens from each of the string's paragraphs.\n",
    "    '''\n",
    "    paragraphs = s.split('\\n\\n') \n",
    "    paragraphs = [p for p in paragraphs if len(p)>0] # Filtering out problematic paragraphs that contain no tokens (possibly because of\n",
    "    return list(map(word_tokenize, paragraphs))      # the use of two consecutive '\\n\\n's)\n",
    "     \n",
    "\n",
    "def treat(series:pd.Series)->List[List[str]]:\n",
    "    '''\n",
    "        Treats the corpus looking for better model fitting.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        series: `pd.Series`\n",
    "            A series contaning our documents.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        The treated texts ready for model consumption.\n",
    "    '''\n",
    "    series = map(str.lower, series)\n",
    "    return list(map(separate_paragraphs, series))\n",
    "\n",
    "# Applying the transformations to our news corpus. \n",
    "corpus = treat(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be831511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T22:22:45.224667Z",
     "iopub.status.busy": "2024-04-18T22:22:45.223862Z",
     "iopub.status.idle": "2024-04-18T22:22:46.048311Z",
     "shell.execute_reply": "2024-04-18T22:22:46.047165Z"
    },
    "papermill": {
     "duration": 0.83245,
     "end_time": "2024-04-18T22:22:46.051008",
     "exception": false,
     "start_time": "2024-04-18T22:22:45.218558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "class MarkovModel:\n",
    "    '''\n",
    "        A Second-Order Markov Model designed for performing article spinning.\n",
    "        \n",
    "        Method\n",
    "        ------\n",
    "        `fit`: It fits the model's probability distributions according to a provided list of paragraphs tokens from a myriad of texts.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        `a2`: The second order transition matrix\n",
    "    '''\n",
    "        \n",
    "            \n",
    "    def __a2(self, X:List[List[List[str]]]):\n",
    "        '''\n",
    "            Builds the second order transition matrix.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[List[str]]\n",
    "                The collection of texts as lists of tokens from each paragraph.\n",
    "        '''\n",
    "        counter = Counter(p[i-1]+'<sep>'+p[i+1]+'<sep>'+p[i] for x in X for p in x for i in range(1, len(p)-1))\n",
    "        denom = Counter(p[i-1]+'<sep>'+p[i+1] for x in X for p in x for i in range(1, len(p)-1))\n",
    "        self.a2 = {}\n",
    "        for key in counter.keys():\n",
    "            i,k,j = key.split('<sep>')\n",
    "            if i not in self.a2.keys():\n",
    "                self.a2[i] = {}\n",
    "            if k not in self.a2[i].keys():\n",
    "                self.a2[i][k] = {}\n",
    "            self.a2[i][k][j] = counter[key]/denom[i+'<sep>'+k]\n",
    "        \n",
    "    def fit(self, X:List[List[List[str]]]):\n",
    "        '''\n",
    "            Constructs the model's vector and state transition matrices.\n",
    "            \n",
    "            Parameter\n",
    "            ---------\n",
    "            `X`: List[List[str]]\n",
    "                The collection of texts as lists of tokens from each paragraph.\n",
    "        '''\n",
    "        #self.__pi(X)\n",
    "        #self.__a(X)\n",
    "        self.__a2(X)\n",
    "        \n",
    "    def spin(self, X:List[List[str]], tokens_per_paragraph:int=2):\n",
    "        '''\n",
    "            Writes a poem\n",
    "        '''\n",
    "        for p in X:\n",
    "            to_remove_idxs = np.random.choice([i for i in range(1, len(p)-1)], size=tokens_per_paragraph, replace=False)\n",
    "#         boundaries = [[(p[i-1], p[+1]) for p in X ]for i in range(1, len(p)-1)]\n",
    "#         return boundaries\n",
    "            \n",
    "model = MarkovModel()\n",
    "model.fit(corpus)\n",
    "#list(model.a2.keys())[:5]\n",
    "# model.fit(corpus[0])\n",
    "# print(model.write())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7114f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T22:22:46.059189Z",
     "iopub.status.busy": "2024-04-18T22:22:46.058780Z",
     "iopub.status.idle": "2024-04-18T22:22:46.068668Z",
     "shell.execute_reply": "2024-04-18T22:22:46.067373Z"
    },
    "papermill": {
     "duration": 0.016738,
     "end_time": "2024-04-18T22:22:46.070961",
     "exception": false,
     "start_time": "2024-04-18T22:22:46.054223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tudo', 'oi'], dtype='<U4')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.choice(['oi', 'tudo'], 2, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f5e56",
   "metadata": {
    "papermill": {
     "duration": 0.002994,
     "end_time": "2024-04-18T22:22:46.077035",
     "exception": false,
     "start_time": "2024-04-18T22:22:46.074041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'> Montar a função de spinning </p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4804690,
     "sourceId": 8129202,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.489425,
   "end_time": "2024-04-18T22:22:47.102962",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-18T22:22:37.613537",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
