{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee017f3-d77a-4b8d-af25-bbfd486dd5da",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Text Summarization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd8557-2b96-4a14-a6f0-79e3c34b7eca",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>   Text Summarization Section Introduction</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Exploraremos por aqui a aplicação de algoritmos de ML na sumarização de documentos.\n",
    "        </li>\n",
    "        <li>\n",
    "            De maneira geral, classificamos sumarizações de textos em duas categorias.\n",
    "            <ul> \n",
    "                <li> \n",
    "                    <i> Extrativa</i> Feita com fragmentos do próprio documento.\n",
    "                </li>\n",
    "                <li> \n",
    "                    <i>Abstrativa:</i> Feita com uma descrição do texto baseada na interpretação do leitor\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            No contexto desta seção, trabalharemos com sumarizações extrativas.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064bb60-c3a2-45af-be2c-8b941dbd8e8c",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>Text Summarization Using Vectors\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Nosso projeto de sumarização consistirá em conferir um score a cada fragmento de um dado texto. Nós selecionaremos os trechos de maior pontuação, para produzirmos nosso resumo.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f5489-1c68-4448-b1b1-ba6ad587c3a6",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Metodologia de Scores</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A pontuação de cada fragmento será feita aplicando um TF-IDF sobre cada trecho (`nltk.sent_tokenize`).\n",
    "        </li>\n",
    "        <li>\n",
    "            Nós extrairemos as pontuações computando a média de cada vetor-linha (np.nanmean).\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844dfb3-8151-42c7-baf7-89c516c3f5da",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>Text Summarization Exercise Prompt\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Tente aplicar a nossa ideia no dataset da BBC, com vários artigos.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a036061-36a4-488f-8d7e-dde2ec17baa4",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> TextRank Intuition\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O TextRank é uma metodologia de sumarização de textos inpirado no algoritmo PageRank do Google.\n",
    "        </li>\n",
    "        <li>\n",
    "            Lembrando que o PageRank computa a probabilidade de o usuário acessar uma determinada página, navegando aleatoriamente pela internet.\n",
    "        </li>\n",
    "        <li>\n",
    "            No caso do TextRank, computaremos as probabilidades mensurando a similaridade cosseno entre cada documento. Isso nos retornará uma matriz $N\\times{N}$.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36187a8-76c5-44e1-9eb3-dad713cc59ed",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> TextRank - How It Really Works (Advanced)\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Iniciamos o TextRank com a matriz de transição de estados $A$ e o vetor $\\pi$, com as probabilidades de estado inicial.\n",
    "        </li>\n",
    "        <li>\n",
    "            O produto de $\\pi A$ pode ser entendido como um vetor $p$ com as probabilidades de estarmos em qualquer um dos estados no time-step $t+1$.\n",
    "        </li>\n",
    "        <li>\n",
    "            Se quisermos saber as probabilidades de nos encontrarmos num certo estado após k time-steps, devemos fazer a seguinte conta:\n",
    "            <center style='margin-top:20px'>\n",
    "                $p(s_k)=\\pi A^{k}$\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c64fd-d295-4524-b5f7-21d9588c3394",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> The Limiting Distribution</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            A Limiting Distribution seria a distribuição de probabilidades obtida após infinitas transições de estado.\n",
    "            <center style='margin-top:20px'>\n",
    "                $\\displaystyle p(s_{\\infty})=\\lim_{t\\to \\infty}\\pi A^{t}$\n",
    "            </center>\n",
    "        </li>\n",
    "        <li style='margin-top:20px'>\n",
    "            Considerando que fizemos infinitas transições, o conjunto de probabilidades para a próxima seria:\n",
    "            <center style='margin-top:20px'>\n",
    "                $p(s_{\\infty})=p(s_{\\infty})A$\n",
    "                <center style='font-size:10px;margin-top:10px'>$\\infty+1=\\infty$</center>\n",
    "            </center>\n",
    "        </li>\n",
    "        <li style='margin-top:20px'>\n",
    "            Acabamos por obter uma distribuição <i> estacionária!</i> Além disso, note que nos colocamos num problema de eigenvalue!\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c53084-b637-4643-8c98-dc4e7f5df0d3",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Perron-Frobenius Theorem</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O Teorema Perron-Frobenius afirma que, caso $A$ seja uma matriz de Markov com todos os seus componentes positivos, podemos dizer que:\n",
    "            <ul> \n",
    "                <li> \n",
    "                    Seu eigenvalue é 1.\n",
    "                </li>\n",
    "                <li>\n",
    "                    A distribuição limitante é a própria distribuição estacionária.\n",
    "                </li>\n",
    "                <li>\n",
    "                    A distribuição limitante é única.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            Portanto, podemos afirmar que o eigenvalue de $A$ é 1, e que a distribuição limitante e estacionária são iguais.\n",
    "        </li>\n",
    "        <li>\n",
    "            <i> Observação:</i> Uma matriz de Markov é aquela cujas linhas têm soma igual a 1 e seus componentes são não-negativos. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51485481-1df7-417f-9296-cba80ea799bf",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Correção de $A$</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Para garantir que nossa matriz de similaridades esteja de acordo com os pré-requisitos do Teorema, deveremos aplicar alguns tratamentos a ela.\n",
    "        </li>\n",
    "        <li> \n",
    "            Em primeiro lugar, devemos dividir os componentes da matriz pela soma de sua respectiva linha - soma das linhas igual a 1.\n",
    "        </li>\n",
    "        <li>\n",
    "            Além disso, temos que garantir que esses componentes sejam maiores do que 0. Se $A$ contém  $M$ componentes, criamos uma matriz $U$ de mesmo formato cujos valores são apenas $\\frac{1}{M}$. Nós então aplicamos uma pequena suavização sobre $A$, de acordo com um hiperparâmetro $\\alpha$.\n",
    "            <center style='margin-top:20px'>\n",
    "                $A=\\alpha{U}+(1-\\alpha)A$\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2c65b8-cad8-40f9-978f-83ee79f972b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master a234727] Aula 80 (7:50)\n",
      " 1 file changed, 43 insertions(+), 7 deletions(-)\n",
      "Enumerating objects: 7, done.\n",
      "Counting objects: 100% (7/7), done.\n",
      "Delta compression using up to 24 threads\n",
      "Compressing objects: 100% (4/4), done.\n",
      "Writing objects: 100% (4/4), 1.02 KiB | 1.02 MiB/s, done.\n",
      "Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
      "To https://github.com/felipesveiga/NLP-Lazy-Programmer.git\n",
      "   2dd7496..a234727  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git add .\n",
    "! git commit -am 'Aula 80 (7:50)' \n",
    "! git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b6583-fcbc-4a98-b15a-12cd8fc56b39",
   "metadata": {},
   "source": [
    "<p style='color:red'> Continuar paper TextRank, por mais que seu algoritmo não tenha nada a ver com o do curso...</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
